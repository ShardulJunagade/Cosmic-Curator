{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d880e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 13. Astronomy: Cosmic Curator â€“ Decoding Galaxy Shapes\n",
    "\n",
    "# **Stakeholders:** Abhay Upparwal, Abdul Qadir Ronak  \n",
    "\n",
    "# **Platform:** [Kaggle](https://www.kaggle.com/competitions/cosmic-curator)\n",
    "\n",
    "# **Team Size:** 1  \n",
    "\n",
    "# ## The Astronomical Observatory\n",
    "\n",
    "# Welcome to the International Virtual Observatory, humanity's most advanced center for galactic research. As a member of the elite Morphological Analysis Team, you're surrounded by massive screens displaying telescope data from across the universe. The observatory has recently received an unprecedented influx of galaxy images from the latest deep-field survey, capturing over 100,000 previously undocumented galaxies. Your director has tasked your team with classifying these cosmic structures, but the volume is overwhelming for human analysis alone. The future of galactic cartography depends on automating this process with precision and reliability.\n",
    "\n",
    "# ## The GalaxyVision System\n",
    "\n",
    "# Your team has been granted access to GalaxyVision, a cutting-edge computational platform specifically designed for astronomical image analysis. This system can process high-resolution, multi-wavelength imagery and extract complex visual features that distinguish different galaxy types. GalaxyVision incorporates specialized image preprocessing techniques to handle the unique challenges of astronomical data, including noise reduction, background subtraction, and normalization across different telescope observations. However, its classification algorithm needs significant improvement to match the expertise of human astronomers.\n",
    "\n",
    "# ## Detailed Problem Statement\n",
    "\n",
    "# Galaxies represent some of the most complex structures in our universe, with morphologies shaped by billions of years of evolution. Edwin Hubble's classification system (the \"tuning fork\") categorizes galaxies primarily as elliptical, spiral, or irregular, but modern astronomy recognizes many more nuanced variations:\n",
    "\n",
    "# Your challenge is to develop a sophisticated machine learning model that can identify these morphological types from telescope images. The model must be robust to variations in image quality, galaxy orientation, redshift effects, and the presence of nearby objects. It should extract meaningful features that astronomers use for classification, such as bulge-to-disk ratio, spiral arm tightness, presence of bars or rings, and signs of interaction.\n",
    "\n",
    "# The classification system you develop will be integrated into the next generation of astronomical surveys, helping scientists understand galaxy formation and evolution across cosmic time. It will also enable researchers to identify rare or unusual galaxies that merit further investigation with more powerful instruments.\n",
    "\n",
    "# ## Dataset\n",
    "\n",
    "# - **Source:** [Kaggle](https://www.kaggle.com/competitions/cosmic-curator)  \n",
    "# - **Format:** JPG images of galaxies (each image is a few hundred pixels wide, with 3 color channels)  \n",
    "# - **Classes:** Multiple galaxy types based on morphological classification  \n",
    "# - **Size:** 916 labelled images  \n",
    "# - **Labels:**  \n",
    "#   - 0: SPIRAL  \n",
    "#   - 1: ELLIPTICAL  \n",
    "#   - 2: UNCERTAIN  \n",
    "# - **Characteristics:** Images vary in resolution, contrast, and background noise, reflecting real-world astronomical data collection challenges  \n",
    "\n",
    "# ## Submission Format\n",
    "\n",
    "# - Csv file in the format (2 columns: asset_id, GalaxyType)  \n",
    "\n",
    "# ## Technical Challenges\n",
    "\n",
    "# Your model must address several specific technical challenges:\n",
    "\n",
    "# - Distinguishing subtle differences between similar galaxy types  \n",
    "# - Processing images with varying levels of detail and quality  \n",
    "# - Extracting meaningful features that correlate with astronomical classification criteria  \n",
    "# - Achieving high accuracy while maintaining computational efficiency  \n",
    "\n",
    "# ## Judging Criteria\n",
    "\n",
    "# Models will be evaluated on a held-out test set of galaxy images with hidden labels. The primary metric is classification accuracy (or macro-averaged F1-score to account for class imbalance). In other words, how many galaxies are correctly classified into the right category. The highest-scoring model (with most correct classifications) wins the contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef9a9d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def set_all_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "seed = 42\n",
    "set_all_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a56f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "TRAIN_DIR = './cosmic-curator/train_images'\n",
    "TEST_DIR = './cosmic-curator/test_images'\n",
    "TRAIN_CSV = './cosmic-curator/train2.csv'\n",
    "OUT_DIR = './results'\n",
    "# delete if exists\n",
    "if os.path.exists(OUT_DIR):\n",
    "    import shutil\n",
    "    shutil.rmtree(OUT_DIR)\n",
    "# create directory\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_TRAIN_CSV = os.path.join(OUT_DIR, 'train.csv')\n",
    "OUT_TEST_CSV = os.path.join(OUT_DIR, 'test.csv')\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 3\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "IMG_SIZE = 424\n",
    "VAL_SPLIT = 0.2\n",
    "SAVE_CHECKPOINT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcad159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Dataset ---\n",
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        asset_id = self.df.loc[idx, 'asset_id']\n",
    "        img_path = os.path.join(self.img_dir, f\"{asset_id}.jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            return image, asset_id\n",
    "        else:\n",
    "            label = int(self.df.loc[idx, 'GalaxyType'])\n",
    "            return image, label\n",
    "\n",
    "# --- Transforms ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8618ab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in train set: 912\n",
      "Images in test set: 412\n",
      "After splitting into train and val sets:\n",
      "Train size: 727\n",
      "Val size: 182\n",
      "Test size: 412\n"
     ]
    }
   ],
   "source": [
    "# --- Load CSV ---\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "print(\"Images in train set:\", len(train_df))\n",
    "# delete the images that are not in the train set\n",
    "train_img_asset_ids = [int(f.split('.')[0]) for f in os.listdir(TRAIN_DIR) if f.endswith('.jpg')]\n",
    "train_df = train_df[train_df['asset_id'].isin(train_img_asset_ids)]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "test_asset_ids = [int(f.split('.')[0]) for f in os.listdir(TEST_DIR) if f.endswith('.jpg')]\n",
    "test_df = pd.DataFrame({'asset_id': test_asset_ids})\n",
    "print(\"Images in test set:\", len(test_df))\n",
    "\n",
    "\n",
    "# --- Train/Val Split ---\n",
    "train_df, val_df = train_test_split(train_df, test_size=VAL_SPLIT, stratify=train_df['GalaxyType'], random_state=seed)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "print(\"After splitting into train and val sets:\")\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Val size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1321b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 727\n",
      "Validation dataset size: 182\n",
      "Test dataset size: 412\n",
      "Train loader size: 23\n",
      "Validation loader size: 6\n",
      "Test loader size: 13\n"
     ]
    }
   ],
   "source": [
    "train_dataset = GalaxyDataset(train_df, TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = GalaxyDataset(val_df, TRAIN_DIR, transform=test_transform)\n",
    "test_dataset = GalaxyDataset(test_df, TEST_DIR, transform=test_transform, is_test=True)\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset)) \n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Train loader size:\", len(train_loader))\n",
    "print(\"Validation loader size:\", len(val_loader))\n",
    "print(\"Test loader size:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28992a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shard\\Desktop\\Hackrush 2025\\Cosmic-Curator\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\shard\\Desktop\\Hackrush 2025\\Cosmic-Curator\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# --- Model ---\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e52a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Loop ---\n",
    "# Initialize lists to store F1 scores\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_val_f1 = 0.0  # To track the best validation F1 score\n",
    "best_model_path = os.path.join(OUT_DIR, 'best_model.pth')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds, train_labels = [], []\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
    "    train_f1_scores.append(train_f1)\n",
    "    train_losses.append(train_loss / len(train_loader))  # Average train loss\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "    val_f1_scores.append(val_f1)\n",
    "    val_losses.append(val_loss / len(val_loader))  # Average validation loss\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_losses[-1]:.4f}, Train F1={train_f1:.4f}, Val Loss={val_losses[-1]:.4f}, Val F1={val_f1:.4f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"âœ… Best model saved with Val F1={best_val_f1:.4f}\")\n",
    "\n",
    "    # Save checkpoint for each epoch if enabled\n",
    "    if SAVE_CHECKPOINT and (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = os.path.join(OUT_DIR, f\"model_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb6cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./results\\model.pth\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecaf3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot F1 Scores ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_f1_scores, label='Train F1', marker='o')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_f1_scores, label='Validation F1', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(OUT_DIR, 'f1_scores_plot.png')\n",
    "plt.savefig(plot_path)\n",
    "plt.show()\n",
    "print(f\"âœ… F1 score plot saved at {plot_path}\")\n",
    "\n",
    "# --- Plot Losses ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_losses, label='Train Loss', marker='o')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_losses, label='Validation Loss', marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plot_path = os.path.join(OUT_DIR, 'losses_plot.png')\n",
    "plt.savefig(plot_path)\n",
    "plt.show()\n",
    "print(f\"âœ… Loss plot saved at {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Test Prediction ---\n",
    "model.eval()\n",
    "predictions = []\n",
    "asset_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ids in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        images = images.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        predictions.extend(preds)\n",
    "        asset_ids.extend(ids.cpu().numpy())  # Convert tensor to numpy array and extend\n",
    "\n",
    "# --- Save Submission ---\n",
    "submission_df = pd.DataFrame({'id': asset_ids, 'GalaxyType': predictions})\n",
    "submission_df.sort_values('id', inplace=True)\n",
    "submission_df.to_csv(OUT_TEST_CSV, index=False)\n",
    "print(f\"Submission saved to {OUT_TEST_CSV}\")\n",
    "print(submission_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
